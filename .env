# Auth
HF_TOKEN=changeme

# Hugging Face cache (persist this path)
HF_HOME=/workspace/huggingface-cache
HUGGINGFACE_HUB_CACHE=/workspace/huggingface-cache

# Optional: compiled kernel caches (persist to avoid re-compiles)
XDG_CACHE_HOME=/workspace/.cache
TRITON_CACHE_DIR=/workspace/.cache/triton
TORCHINDUCTOR_CACHE_DIR=/workspace/.cache/torchinductor

# API auth
SECRET_TOKEN=changeme

# Model config
MODEL_NAME=zai-org/GLM-4.6
TORCH_DTYPE=bfloat16
TRUST_REMOTE_CODE=true

# Parallel mode selection:
# - tp: use tensor-parallel tp_plan="auto" and ignore device_map
# - device_map: use DEVICE_MAP and do not use TP
PARALLEL_MODE=tp
DEVICE_MAP=auto

# Attention implementation preference
ATTN_IMPLEMENTATION=flash_attention_2

# Tokenization/padding
TOKENIZER_PADDING_SIDE=left
PAD_TO_MULTIPLE_OF=64
MAX_INPUT_TOKENS=512
ALLOWED_MAX_NEW_TOKENS=64,128,256,512

# Optional advanced optimization (enable only if you keep shapes constant)
STATIC_KV_CACHE=false

# Constrained vocab prebuild
PREBUILD_PREFIX=true
PREBUILD_WORD_COUNTS=3000
PREBUILD_LANGS=es

# Batch job
BATCH_JOB_PIPELINE_SIZE=8

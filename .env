# Authentication
SECRET_TOKEN=changeme

# Model config
# Previous model: google/gemma-3-27b-it
MODEL_NAME=moonshotai/Kimi-K2-Instruct-0905
# DEVICE_MAP can be: "cuda", "auto", "cpu" (use cuda/auto on GPU instances)
DEVICE_MAP=cuda
# NEW: Set to true if the model requires executing custom code from the Hub (e.g., Kimi-K2, Phi-3, DeepSeek)
TRUST_REMOTE_CODE=true

# Precision / quantization
# TORCH_DTYPE can be: float32 | float16 | bfloat16 | fp32 | fp16 | bf16
TORCH_DTYPE=bfloat16
# To use 8-bit or 4-bit, set true and install bitsandbytes
# Note: Kimi-K2 is a large model; ensure sufficient VRAM/RAM.
LOAD_IN_8BIT=false
LOAD_IN_4BIT=false

# Default system prompts (leave empty for no system prompt)
DEFAULT_SYSTEM_PROMPT_EN=
DEFAULT_SYSTEM_PROMPT_ES=

# Prebuild constrained vocab prefix functions at startup
PREBUILD_PREFIX=true
# Comma-separated list of word counts to prebuild
PREBUILD_WORD_COUNTS=3000

# Hugging Face Token (if required for gated models)
HF_TOKEN=changeme

HF_HOME="/workspace/huggingface-cache"

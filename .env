# Hugging Face auth (if needed)
HF_TOKEN=changeme

# Hugging Face caches (persist these directories between runs)
HF_HOME=/workspace/huggingface-cache
TRANSFORMERS_CACHE=/workspace/huggingface-cache
HUGGINGFACE_HUB_CACHE=/workspace/huggingface-cache

# Optional: cache for compiled kernels (helps avoid repeated Triton/torch compilation)
XDG_CACHE_HOME=/workspace/.cache
TRITON_CACHE_DIR=/workspace/.cache/triton
TORCHINDUCTOR_CACHE_DIR=/workspace/.cache/torchinductor

# Authentication for your API
SECRET_TOKEN=changeme

# Model config
MODEL_NAME=zai-org/GLM-4.6-FP8
TORCH_DTYPE=bf16
DEVICE_MAP=cuda
TRUST_REMOTE_CODE=true

# Constrained vocab prebuild
PREBUILD_PREFIX=true
PREBUILD_WORD_COUNTS=3000
PREBUILD_LANGS=es

# Batch job
BATCH_JOB_PIPELINE_SIZE=8

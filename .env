# Auth
HF_TOKEN=
# API auth
# IMPORTANT: Set a strong token in production.
SECRET_TOKEN=changeme

# Model config
MODEL_NAME=TheDrummer/Cydonia-24B-v4.2.0
TORCH_DTYPE=bf16
TRUST_REMOTE_CODE=true
DEVICE_MAP=auto

# Attention implementation (sdpa, flash_attention_2, eager)
ATTN_IMPLEMENTATION=sdpa

# Tokenization/padding
TOKENIZER_PADDING_SIDE=left
PAD_TO_MULTIPLE_OF=16
MAX_INPUT_TOKENS=512
ALLOWED_MAX_NEW_TOKENS=64,128,256,512

# Optional advanced optimization
STATIC_KV_CACHE=false

# Constrained vocab prebuild
PREBUILD_PREFIX=true
PREBUILD_WORD_COUNTS=1000
PREBUILD_LANGS=es

# Batch job
BATCH_JOB_PIPELINE_SIZE=4

# In-process GPU generation concurrency (1 = fully serialized)
GENERATION_MAX_CONCURRENCY=1

# Deepseek V3 MoE grouped GEMM optimization
# Enable these when using Deepseek V3 models (e.g., deepseek-ai/DeepSeek-V3)
# Note: Requires grouped_gemm to be installed: pip install grouped_gemm
# USE_GROUPED_GEMM=false
# FUSE_EXPERTS_ON_STARTUP=true

# Example Deepseek V3 configuration:
# MODEL_NAME=deepseek-ai/DeepSeek-V3
# USE_GROUPED_GEMM=true
# FUSE_EXPERTS_ON_STARTUP=true
# TORCH_DTYPE=bf16
# TRUST_REMOTE_CODE=true

# Where to find wordlists (defaults to ./wordlists)
WORDLIST_DIR=wordlists

# Optional: directory for batch job temp files (defaults to OS temp)
# BATCH_JOB_TEMP_DIR=/tmp

# HF cache dir (optional)
# HF_HOME=/workspace/huggingface-cache

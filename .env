# Auth
HF_TOKEN=
SECRET_TOKEN=changeme

# Model config
MODEL_NAME=zai-org/GLM-4.6
TORCH_DTYPE=bf16
TRUST_REMOTE_CODE=true
DEVICE_MAP=auto
ATTN_IMPLEMENTATION=sdpa

TOKENIZER_PADDING_SIDE=left
PAD_TO_MULTIPLE_OF=16
MAX_INPUT_TOKENS=512
ALLOWED_MAX_NEW_TOKENS=64,128,256,512
STATIC_KV_CACHE=false

# Grouped GEMM / MoE
# USE_GROUPED_GEMM enables grouped_gemm forward path.
# LOAD_FUSED_EXPERTS means the checkpoint already has fused expert weights.
# FUSE_ON_CPU_BEFORE_SHARD ensures we force CPU load before fusion even if DEVICE_MAP=auto is set.
USE_GROUPED_GEMM=true
LOAD_FUSED_EXPERTS=false
FUSE_ON_CPU_BEFORE_SHARD=true

# Distributed / FSDP
USE_FSDP=false
FSDP_AUTO_WRAP=false
FSDP_MIN_PARAMS=10000000
DISTRIBUTED_BACKEND=nccl

PREBUILD_PREFIX=true
PREBUILD_WORD_COUNTS=1000
PREBUILD_LANGS=es

BATCH_JOB_PIPELINE_SIZE=4
GENERATION_MAX_CONCURRENCY=1
WORDLIST_DIR=wordlists
